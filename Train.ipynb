{"cells":[{"cell_type":"markdown","metadata":{"id":"17g5BxJoClPB"},"source":["Inserire il path all'interno del quale è contenuto il file .ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qH8sGm0sCkbX"},"outputs":[],"source":["path = \"/content/drive/MyDrive/CODICE FINALE/\""]},{"cell_type":"markdown","metadata":{"id":"-ySwOH0qULku"},"source":["Unzip del database"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXLon2MKT8rF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677177829226,"user_tz":-60,"elapsed":21118,"user":{"displayName":"Cont est","userId":"12913621564358958738"}},"outputId":"25ca9185-3493-44a9-9380-352d0146f264"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Inserire il path all'interno del quale è contenuto il construction set"],"metadata":{"id":"SrO2KnWI6jJi"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"e4Luoe2NUKiT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677261758025,"user_tz":-60,"elapsed":7,"user":{"displayName":"Cont est","userId":"12913621564358958738"}},"outputId":"b6b395a1-17b9-4a15-bf56-17af4376095f"},"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open /content/drive/MyDrive/OCTchallenge_new.zip, /content/drive/MyDrive/OCTchallenge_new.zip.zip or /content/drive/MyDrive/OCTchallenge_new.zip.ZIP.\n"]}],"source":["!unzip \"/content/drive/MyDrive/OCTchallenge_new.zip\" # inserire path completa in cui si trovano i dati"]},{"cell_type":"markdown","metadata":{"id":"vRI75G7uT9YI"},"source":["# Installazione di MONAI ed esportazione delle librerie"]},{"cell_type":"markdown","source":["Istallazione di MONAI"],"metadata":{"id":"QJSt8iqU6wS_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4UKveulRSy0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677177951374,"user_tz":-60,"elapsed":60455,"user":{"displayName":"Cont est","userId":"12913621564358958738"}},"outputId":"6415d282-875e-46e2-d815-0291ac464da3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting monai[all]\n","  Downloading monai-1.1.0-202212191849-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.8/dist-packages (from monai[all]) (1.13.1+cu116)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from monai[all]) (1.22.4)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (from monai[all]) (3.0.2)\n","Collecting itk>=5.2\n","  Downloading itk-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (8.3 kB)\n","Collecting fire\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting imagecodecs\n","  Downloading imagecodecs-2023.1.23-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from monai[all]) (3.1.0)\n","Collecting pynrrd\n","  Downloading pynrrd-1.0.0-py2.py3-none-any.whl (19 kB)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from monai[all]) (0.14.1+cu116)\n","Collecting nni\n","  Downloading nni-2.10-py3-none-manylinux1_x86_64.whl (56.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tifffile in /usr/local/lib/python3.8/dist-packages (from monai[all]) (2023.2.3)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.8/dist-packages (from monai[all]) (0.18.3)\n","Collecting openslide-python==1.1.2\n","  Downloading openslide-python-1.1.2.tar.gz (316 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 KB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ninja\n","  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from monai[all]) (5.4.8)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from monai[all]) (2.11.2)\n","Collecting einops\n","  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from monai[all]) (1.3.5)\n","Collecting pytorch-ignite==0.4.10\n","  Downloading pytorch_ignite-0.4.10-py3-none-any.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.1/264.1 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cucim>=22.8.1\n","  Downloading cucim-23.2.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from monai[all]) (3.5.3)\n","Collecting transformers<4.22\n","  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mlflow\n","  Downloading mlflow-2.1.1-py3-none-any.whl (16.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydicom\n","  Downloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from monai[all]) (4.3.3)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.8/dist-packages (from monai[all]) (0.99)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from monai[all]) (6.0)\n","Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from monai[all]) (4.4.0)\n","Collecting optuna\n","  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from monai[all]) (7.1.2)\n","Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.8/dist-packages (from monai[all]) (4.64.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from pytorch-ignite==0.4.10->monai[all]) (23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from cucim>=22.8.1->monai[all]) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown>=4.4.0->monai[all]) (1.15.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown>=4.4.0->monai[all]) (2.25.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=4.4.0->monai[all]) (4.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=4.4.0->monai[all]) (3.9.0)\n","Collecting itk-core==5.3.0\n","  Downloading itk_core-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (81.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-numerics==5.3.0\n","  Downloading itk_numerics-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (58.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-registration==5.3.0\n","  Downloading itk_registration-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (26.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-io==5.3.0\n","  Downloading itk_io-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (25.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.6/25.6 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-segmentation==5.3.0\n","  Downloading itk_segmentation-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (16.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-filtering==5.3.0\n","  Downloading itk_filtering-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (73.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->monai[all]) (2.9.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->monai[all]) (3.0)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->monai[all]) (1.7.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->monai[all]) (1.4.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->monai[all]) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->monai[all]) (4.38.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->monai[all]) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->monai[all]) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->monai[all]) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8->monai[all]) (4.5.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.22->monai[all]) (2022.6.2)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->monai[all]) (2.2.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->monai[all]) (5.12.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->monai[all]) (22.2.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->monai[all]) (0.19.3)\n","Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (0.4)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (0.4.3)\n","Collecting gunicorn<21\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic<2\n","  Downloading alembic-1.9.4-py3-none-any.whl (210 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.5/210.5 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow<11,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (9.0.0)\n","Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (2.2.1)\n","Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (1.4.46)\n","Requirement already satisfied: Flask<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (1.1.4)\n","Collecting shap<1,>=0.40\n","  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting databricks-cli<1,>=0.8.7\n","  Downloading databricks-cli-0.17.4.tar.gz (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting querystring-parser<2\n","  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (2.11.3)\n","Collecting packaging\n","  Downloading packaging-22.0-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting importlib-metadata!=4.7.0,<6,>=3.7.0\n","  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n","Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (3.19.6)\n","Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (3.4.1)\n","Collecting gitpython<4,>=2.1.0\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (1.0.2)\n","Collecting docker<7,>=4.0.0\n","  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz<2023 in /usr/local/lib/python3.8/dist-packages (from mlflow->monai[all]) (2022.7.1)\n","Requirement already satisfied: astor in /usr/local/lib/python3.8/dist-packages (from nni->monai[all]) (0.8.1)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting websockets>=10.1\n","  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting json-tricks>=3.15.5\n","  Downloading json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n","Collecting responses\n","  Downloading responses-0.22.0-py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting schema\n","  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.8/dist-packages (from nni->monai[all]) (2.7.1)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.8/dist-packages (from nni->monai[all]) (3.6.0)\n","Collecting PythonWebHDFS\n","  Downloading PythonWebHDFS-0.2.3-py3-none-any.whl (10 kB)\n","Collecting cmaes>=0.9.1\n","  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n","Collecting colorlog\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Collecting nptyping\n","  Downloading nptyping-2.5.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->monai[all]) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->monai[all]) (57.4.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->monai[all]) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->monai[all]) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->monai[all]) (0.38.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->monai[all]) (1.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->monai[all]) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->monai[all]) (2.16.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->monai[all]) (1.51.1)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyjwt>=1.7.0\n","  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->monai[all]) (3.2.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->monai[all]) (0.8.10)\n","Collecting urllib3>=1.26.0\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websocket-client>=0.32.0\n","  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests\n","  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->monai[all]) (1.1.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->monai[all]) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->monai[all]) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->monai[all]) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->monai[all]) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow->monai[all]) (3.14.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<4,>=2.11->mlflow->monai[all]) (2.0.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.22->monai[all]) (2.10)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.22->monai[all]) (3.0.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.22->monai[all]) (2022.12.7)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2->mlflow->monai[all]) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2->mlflow->monai[all]) (3.1.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow->monai[all]) (0.56.4)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow->monai[all]) (2.0.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prettytable->nni->monai[all]) (0.2.6)\n","Collecting simplejson\n","  Downloading simplejson-3.18.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.22->monai[all]) (1.7.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from responses->nni->monai[all]) (0.10.2)\n","Collecting types-toml\n","  Downloading types_toml-0.10.8.5-py3-none-any.whl (4.5 kB)\n","Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.8/dist-packages (from schema->nni->monai[all]) (0.5.5)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->monai[all]) (0.4.8)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap<1,>=0.40->mlflow->monai[all]) (0.39.1)\n","Building wheels for collected packages: openslide-python, fire, databricks-cli\n","  Building wheel for openslide-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openslide-python: filename=openslide_python-1.1.2-cp38-cp38-linux_x86_64.whl size=27190 sha256=7ddd06c95ce7ec3fb2c25a4669e98c604fb2bd72bed27be4727f4457e96b65a5\n","  Stored in directory: /root/.cache/pip/wheels/54/f7/99/15df0aea11eefca84d990052a0133ead40443e8abe22d18a11\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116949 sha256=4dd3e10ade72bf9b56bd4ceea3904a931ec1bb7cf7f7f57307cea9a706f42b58\n","  Stored in directory: /root/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142894 sha256=5159d5d7ae02035016b865d80f2d5408dbb662229875df96b848c2c6422aa8f4\n","  Stored in directory: /root/.cache/pip/wheels/48/7c/6e/4bf2c1748c7ecf994ca951591de81674ed6bf633e1e337d873\n","Successfully built openslide-python fire databricks-cli\n","Installing collected packages: types-toml, tokenizers, ninja, json-tricks, websockets, websocket-client, urllib3, smmap, slicer, simplejson, schema, querystring-parser, pyjwt, pydicom, packaging, openslide-python, nptyping, Mako, itk-core, importlib-metadata, imagecodecs, gunicorn, fire, einops, cucim, colorlog, colorama, cmaes, tensorboardX, requests, pytorch-ignite, pynrrd, monai, itk-numerics, itk-io, gitdb, alembic, shap, responses, PythonWebHDFS, optuna, itk-filtering, huggingface-hub, gitpython, docker, databricks-cli, transformers, nni, mlflow, itk-segmentation, itk-registration, itk\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 23.0\n","    Uninstalling packaging-23.0:\n","      Successfully uninstalled packaging-23.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 6.0.0\n","    Uninstalling importlib-metadata-6.0.0:\n","      Successfully uninstalled importlib-metadata-6.0.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.25.1\n","    Uninstalling requests-2.25.1:\n","      Successfully uninstalled requests-2.25.1\n","Successfully installed Mako-1.2.4 PythonWebHDFS-0.2.3 alembic-1.9.4 cmaes-0.9.1 colorama-0.4.6 colorlog-6.7.0 cucim-23.2.0 databricks-cli-0.17.4 docker-6.0.1 einops-0.6.0 fire-0.5.0 gitdb-4.0.10 gitpython-3.1.31 gunicorn-20.1.0 huggingface-hub-0.12.1 imagecodecs-2023.1.23 importlib-metadata-5.2.0 itk-5.3.0 itk-core-5.3.0 itk-filtering-5.3.0 itk-io-5.3.0 itk-numerics-5.3.0 itk-registration-5.3.0 itk-segmentation-5.3.0 json-tricks-3.16.1 mlflow-2.1.1 monai-1.1.0 ninja-1.11.1 nni-2.10 nptyping-2.5.0 openslide-python-1.1.2 optuna-3.1.0 packaging-22.0 pydicom-2.3.1 pyjwt-2.6.0 pynrrd-1.0.0 pytorch-ignite-0.4.10 querystring-parser-1.2.4 requests-2.28.2 responses-0.22.0 schema-0.7.5 shap-0.41.0 simplejson-3.18.3 slicer-0.0.7 smmap-5.0.0 tensorboardX-2.6 tokenizers-0.12.1 transformers-4.21.3 types-toml-0.10.8.5 urllib3-1.26.14 websocket-client-1.5.1 websockets-10.4\n"]}],"source":["!pip install 'monai[all]'"]},{"cell_type":"markdown","source":["Esportazione delle librerie"],"metadata":{"id":"xkJixINF6zzW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tgb4UFbuSGvb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677177977442,"user_tz":-60,"elapsed":26113,"user":{"displayName":"Cont est","userId":"12913621564358958738"}},"outputId":"94d62491-c677-476a-871d-b346d236c527"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pynrrd in /usr/local/lib/python3.8/dist-packages (1.0.0)\n","Requirement already satisfied: nptyping in /usr/local/lib/python3.8/dist-packages (from pynrrd) (2.5.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from pynrrd) (4.5.0)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from pynrrd) (1.22.4)\n"]}],"source":["!pip install pynrrd\n","\n","import os\n","from monai.inferers import SimpleInferer\n","import nrrd\n","\n","from monai.utils import set_determinism\n","from monai.networks.nets import UNet\n","from monai.networks.layers import Norm\n","from monai.config import print_config\n","from monai.metrics import DiceMetric,ConfusionMatrixMetric\n","\n","import monai\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch \n","import PIL\n","from PIL import ImageEnhance\n","\n","from tqdm import tqdm\n","from skimage.io import imread, imshow, imsave\n","from skimage.transform import resize\n","\n","from skimage.transform import rotate\n","from scipy.ndimage import binary_fill_holes, median_filter, gaussian_filter,binary_dilation, binary_erosion\n","from skimage.measure import label, regionprops, regionprops_table\n","import matplotlib.patches as mpatches\n","\n","import skimage.io as io\n","from skimage import morphology,exposure\n","import cv2\n","import pandas as pd\n","\n","import torch\n","from torchvision import transforms\n","from PIL import Image, ImageFilter, ImageEnhance\n","\n","from monai.transforms import (\n","    AsDiscrete,\n","    DataStatsd,\n","    AddChanneld,\n","    Compose,\n","    Activations,\n","    LoadImage,\n","    LoadImaged,\n","    Resize,\n","    Resized,\n","    RandFlipd,\n","    ScaleIntensityRange,\n","    ScaleIntensityRanged,\n","    DataStats,\n","    AsChannelFirstd,\n","    AsDiscreted,\n","    ToTensord,\n","    EnsureType,\n","    ThresholdIntensityd,\n","    SpatialCropd,\n","    CropForegroundd,\n","    EnsureChannelFirstd,\n","    RandSpatialCropSamplesd,\n","    Orientationd,\n","    Spacingd,\n","    DataStatsd,\n","    RandRotate90d,\n","    RandRotated,\n","    RandAxisFlipd,\n","    AdjustContrastd,\n",")\n","\n","from monai.data import (\n","    DataLoader,\n","    CacheDataset,\n","    PILReader,\n","    ITKReader,\n","    NrrdReader,\n","    IterableDataset,\n","    decollate_batch,\n",")"]},{"cell_type":"markdown","metadata":{"id":"kuu_l8ExVSIw"},"source":["# Definizione dei path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iu0TFlQvVJCy"},"outputs":[],"source":["current_dir = os.getcwd()\n","dataset_name = 'new dataset' #nome della cartella in cui è contenuto il construction set\n","\n","#Poichè all'interno delle cartelle di training e validation vi sono due sotto-cartelle (w6_d5 e w6_d7), \n","#sono state create rispettivamente due liste ordinate (sia per le immagini che per le maschere) per training e validation.\n","\n","training1_volumes_path = os.path.join(dataset_name,'Volumes','training','w6_d5')\n","training2_volumes_path = os.path.join(dataset_name,'Volumes','training','w6_d7')\n","\n","validation1_volumes_path = os.path.join(dataset_name,'Volumes','validation','w2_d7')\n","validation2_volumes_path = os.path.join(dataset_name,'Volumes','validation','w6_d9')\n","\n","training1_masks_path = os.path.join(dataset_name,'masks','training','w6_d5')\n","training2_masks_path = os.path.join(dataset_name,'masks','training','w6_d7')\n","\n","validation1_masks_path = os.path.join(dataset_name,'masks','validation','w2_d7')\n","validation2_masks_path = os.path.join(dataset_name,'masks','validation','w6_d9')\n","\n","#liste ordinate per le immagini di training --> 4608 elementi\n","training1_volumes = sorted(os.listdir(training1_volumes_path))\n","training1_volumes = training1_volumes[1:] #al fine di eliminare il primo elemento che è \".DS_Store\", ovvero un file nascosto con un formato proprietario creato da macOS \n","training2_volumes = sorted(os.listdir(training2_volumes_path))\n","\n","#liste ordinate per le maschere di training\n","training1_masks = sorted(os.listdir(training1_masks_path))\n","training2_masks = sorted(os.listdir(training2_masks_path))\n","\n","#liste ordinate per le immagini di validazione --> 1024 elementi \n","validation1_volumes = sorted(os.listdir(validation1_volumes_path))\n","validation2_volumes = sorted(os.listdir(validation2_volumes_path))\n","\n","#liste ordinate per le maschere di validazione\n","validation1_masks = sorted(os.listdir(validation1_masks_path))\n","validation2_masks = sorted(os.listdir(validation2_masks_path))"]},{"cell_type":"markdown","metadata":{"id":"Ictw2yudbq7E"},"source":["# Creazione del training e validation set dict"]},{"cell_type":"markdown","source":["Creazione del training set dict"],"metadata":{"id":"psStVAjd8HtZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCWvR5MXaUG4"},"outputs":[],"source":["training_data = [] # Inizializzazione della lista di dizionari del training set\n","for i in range(len(training1_volumes)): #ciclo sul primo set di immagini di training \n","    tempDict = {\n","        'image': os.path.join(training1_volumes_path, training1_volumes[i]),\n","        'segmentation': os.path.join(training1_masks_path, training1_masks[i])}\n","    \n","    training_data.append(tempDict)\n","\n","for i in range(len(training2_volumes)): #ciclo sul secondo set di immagini di training\n","\n","    tempDict = {\n","        'image': os.path.join(training2_volumes_path, training2_volumes[i]),\n","        'segmentation': os.path.join(training2_masks_path,training2_masks[i])}\n","    \n","    training_data.append(tempDict)"]},{"cell_type":"markdown","metadata":{"id":"Cz7ec1Pdbu12"},"source":["Creazione del validation set dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fvf72u3Pbqgy"},"outputs":[],"source":["validation_data = [] # Inizializzazione della lista di dizionari del validation set\n","for i in range(len(validation1_volumes)): #ciclo sul primo set di immagini di validazione\n","\n","    tempDict = {\n","        'image': os.path.join(validation1_volumes_path, validation1_volumes[i]),\n","        'segmentation': os.path.join(validation1_masks_path, validation1_masks[i])}\n","    \n","    validation_data.append(tempDict)\n","\n","for i in range(len(validation2_volumes)): #ciclo sul secondo set di immagini di validazione\n","    tempDict = {\n","        'image': os.path.join(validation2_volumes_path, validation2_volumes[i]),\n","        'segmentation': os.path.join(validation2_masks_path,validation2_masks[i])}\n","    \n","    validation_data.append(tempDict)"]},{"cell_type":"markdown","metadata":{"id":"DlrkomGX430P"},"source":["# Pre- e Post- processing"]},{"cell_type":"markdown","source":["Funzione che permette di generare una maschera binaria, tramite la tecnica del global thresholding, a partire dall'immagine pre elaborata.\n","\n","*   x: immagine 2D pre-processata\n","*   Threshold: soglia per il global thresholding"],"metadata":{"id":"o1b6-6IJvxQC"}},{"cell_type":"code","source":["def img_to_mask(x,threshold): \n","  mask= x.copy()\n","  mask[mask<threshold] = 0 \n","  mask[mask>threshold] = 1\n","  return mask"],"metadata":{"id":"GyVfmARpvtPx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Funzione che permette di gestire gli artefatti ti dipo lineare\n","\n","*   x: immagine 2D pre-processata\n","*   mask: maschera ottenuta dalla funzione img_to_mask\n","\n"],"metadata":{"id":"y0CHHG6hn9uO"}},{"cell_type":"code","source":["def delartifact(x,mask):\n","  kernel = np.ones((3,3)) #Definizione dell'elemento strutturale (kernel 3x3)\n","  dilated = binary_dilation(mask, structure=kernel) # Dilatazione degli elementi con intensità di pixel=1\n","  mask= binary_fill_holes(mask) \n","  mask = binary_erosion(dilated,structure=kernel) # Erosione degli elementi con intensità di pixel=1\n","\n","  image_mask= x*mask #Maschera sovrapposta all'immagine\n","  regions = regionprops(label(mask),image_mask) # Calcola le proprietà delle regioni\n","\n","  for region in regions:\n","    tumor_coords = region.coords # Estrazione delle coordinate dei pixel all'interno della regione del tumore      \n","    minr, minc, maxr, maxc = region.bbox #Estrazione delle coordinate della bounding box\n","\n","    if ((maxr-minr)>50 and (maxc-minc)<35) or ((maxr-minr)>150 and (maxc-minc)<37) or ((maxr-minr)<37 and (maxc-minc)>150) or ((maxr-minr)>20 and (maxc-minc)<8): #Condizione per eliminare l'artefatto\n","      x[tumor_coords[:, 0], tumor_coords[:, 1]]=np.min(x) #eliminazione dell'artefatto dall'immagine\n","\n","  return x"],"metadata":{"id":"Qfcm2p0Ona1r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HC-3C9wp8Kww"},"source":["Definizione di una funzione di pre processing\n","\n","\n","*   x: immagine 2D originale\n","*   y: maschera manuale associata all'immagine x\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EMFj7GU96RMG"},"outputs":[],"source":["def preprocessing(x,y):\n","  \n","  #Eliminazione del canale --> (256,256)\n","  x = x.squeeze()\n","  y = y.squeeze()\n","\n","  #Conversione delle immagini in formato numpy\n","  x = x.cpu().numpy()\n","  y = y.cpu().numpy()\n","  \n","  #Applicazione del filtro mediano\n","  x = median_filter(x,3)\n","\n","  #Gestione degli artefatti\n","  mask = img_to_mask(x,1700)\n","  condizione = np.count_nonzero(mask)\n","  if condizione !=0: #se la maschera ha almeno un elemento uguale a 1\n","    x = delartifact(x,mask)\n","  \n","  return x,y"]},{"cell_type":"markdown","metadata":{"id":"V4kbsuhe0df1"},"source":["Definizione di una funzione di post processing\n","\n","*   x: maschera automatica in output al modello \n","*   y: maschera manuale associata all'immagine z\n","*   z: immagine 2D pre-processata \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Vv2cMPo0ftf"},"outputs":[],"source":["def postprocessing(x,y,z):\n","  \n","  #Conversione delle immagini in formato numpy\n","  x = x.cpu().numpy()\n","  y = y.cpu().numpy()\n","  z = z.cpu().numpy()\n","\n","  #Riempimento dei buchi della maschera automatica\n","  x = binary_fill_holes(x)\n","\n","  return x,y,z"]},{"cell_type":"markdown","metadata":{"id":"8nYuKeHYi4u3"},"source":["# Creazione dei Dataset e DataLoader per le fasi di Training e Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yM9TUKLe35F"},"outputs":[],"source":["train_transforms = Compose(\n","    [\n","        LoadImaged(keys=[\"image\",\"segmentation\"],image_only=False, reader=ITKReader()), # caricamento dell'immagine e della segmentazione\n","        EnsureChannelFirstd(keys=[\"image\",\"segmentation\"]), # aggiunge il canale all' immagine e alla segmentazione ottenendo il formato channel-first da (NxN) a (1xNxN)\n","        Resized(keys=[\"image\", \"segmentation\"], spatial_size=[256,256]), # resize dell'immagine a 256x256\n","        AsDiscreted(keys=[\"segmentation\"],threshold=0.5), # porta la segmentazione in formato binario con soglia 0.5\n","        AdjustContrastd(keys=[\"image\"],gamma=1.5),\n","     \n","        # Operazioni di data augmentation: \n","        RandRotated(keys=[\"image\", \"segmentation\"], range_x=[-0.1, 0.1], prob=0.3, padding_mode=\"zeros\"),\n","    \n","        #DataStatsd(keys = ['image', 'segmentation']), #Per verificare le dimensioni finali dell'immagine\n","        ToTensord(keys=[\"image\", \"segmentation\"]), # per portare immagini e segmentazioni da formato PIL a un torch tensor da dare in input alla rete\n","    ]\n",")\n","\n","val_transforms = Compose(\n","    [\n","        LoadImaged(keys=[\"image\",\"segmentation\"],image_only=False, reader=ITKReader()), # caricamento dell'immagine e della segmentazione\n","        EnsureChannelFirstd(keys=[\"image\",\"segmentation\"]), # aggiunge il canale all' immagine e alla segmentazione ottenendo il formato channel-first da (NxN) a (1xNxN)\n","        Resized(keys=[\"image\", \"segmentation\"], spatial_size=[256,256]), # resize dell'immagine a 256x256\n","        AsDiscreted(keys=[\"segmentation\"],threshold=0.5), # porta la segmentazione in formato binario con soglia 0.5 (abbiamo modificato il range di valori nella trasformazione precedente)\n","        AdjustContrastd(keys=[\"image\"],gamma=1.5),\n","        ToTensord(keys=[\"image\", \"segmentation\"]), # per portare immagini e segmentazioni da formato PIL a un torch tensor da dare in input alla rete\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7b8kOWioiq_L"},"outputs":[],"source":["batch_size= 32\n","\n","#Creazione di un oggetto iterabile da cui è possibile estrarre in maniera sequenziale dei dati\n","#In input vengono fornite le coppie immagine-segmentazione e le trasformazioni da applicare\n","train_ds = IterableDataset(data = training_data, transform = train_transforms)\n","\n","wks = 0 # definisce il numero di workers (core della CPU da utilizzare) per caricare le immagini\n","\n","# definizione dell'oggetto Dataloader che si occuperà di caricare le immagini in maniera sequenziale\n","# definendo i vari batch durante l'allenamento\n","train_loader = DataLoader(train_ds, batch_size=batch_size, num_workers=wks, pin_memory=True, shuffle=False)\n","\n","#Le stesse operazioni vengono ripetute per il validation\n","val_ds = IterableDataset(data = validation_data, transform = val_transforms)\n","val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=wks, pin_memory=True, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"hF1AjY2WB-gQ"},"source":["# Creazione della rete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftVOrL1hB93E"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Definizione del device da utilizzare: GPU\n","\n","model = UNet(\n","    spatial_dims=2,\n","    in_channels=1,\n","    out_channels=1,\n","    channels=(16, 32, 64, 128, 256),\n","    strides=(2, 2, 2, 2),\n","    num_res_units=2,\n","    norm=Norm.BATCH, #feature normalization type and arguments (Defaults to instance norm)\n",").to(device)\n","\n","# Definizione della loss function\n","from monai.losses.dice import DiceCELoss\n","loss_function = DiceCELoss(sigmoid = True) \n","\n","# Definizione dell'ottimizatore\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","\n","# Definizione delle trasformazioni di post-processing\n","post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)]) \n","post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])\n","post_image = Compose([EnsureType()])\n","\n","# Definizione del tipo di Inferenza da applicare con il modello allenato\n","inferer = SimpleInferer()\n","\n","# Definizione un seed per renderere ripetibili tutte le opearazioni che andiamo ad effettuare\n","# Questa operazione non è sempre possibile in quanto alcune operazioni hanno condizioni aleatorie intrinseche,\n","# in quel caso possono essere segnalati errori e warning che risolviamo eliminando questa condizione\n","set_determinism(seed=46)"]},{"cell_type":"markdown","metadata":{"id":"ELzPJZloCIGI"},"source":["**Creazione cartella** per salvataggio dei risultati relativi all'allenamento della rete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0MhoVNMCKhW","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"error","timestamp":1677177982547,"user_tz":-60,"elapsed":549,"user":{"displayName":"Cont est","userId":"12913621564358958738"}},"outputId":"11acf150-0925-43f8-aace-d7e673b9f898"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-928a0f04a83b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpFd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpFd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#crea la directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CODICE FINALE/Validation-Snapshot'"]}],"source":["expFd = os.path.join(path,'Validation-Snapshot')\n","\n","if not os.path.isdir(expFd):\n","  os.mkdir(expFd) #crea la directory"]},{"cell_type":"markdown","metadata":{"id":"74dWE_JN7_zC"},"source":["# SALVATAGGIO IMMAGINI PRE-PROCESSING  -*NON ESEGUIRE*-"]},{"cell_type":"markdown","source":["**Creazione cartella** per salvataggio dei risultati relativi alla fase di pre-processing"],"metadata":{"id":"yHOkBKl0r2xE"}},{"cell_type":"code","source":["expFd2 = os.path.join(path,'Pre-processing')\n","\n","if not os.path.isdir(expFd2):\n","  os.mkdir(expFd2) #crea la directory"],"metadata":{"id":"s8_-Q9k4r1C0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SU-ZhzUs83xy"},"source":["Funzione per il salvataggio delle immagini in formato .nrrd\n","\n","*   list_val_output: lista di tensori con shape [1,1,256,256]\n","*   stepFd: path della cartella all'interno della quale salvare le immagini\n","*   fdName: path dell'immagine\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6mVzO7e84Yg"},"outputs":[],"source":["def Savenrrd(list_val_output,stepFd,fdName):\n","  \n","  #Estrazione del nome dell'immagine a partire da fdName\n","  parts = fdName.split('/') # suddivide la stringa in base al separatore '/'\n","  parts = parts[4:] # elimina la prima parte della lista\n","  string = '/'.join(parts) # ricostruisci la stringa eliminando la parte specificata\n","\n","  file_path = os.path.join(stepFd, '{}.nrrd'.format(string[:-4] + '_intera')) # crea il percorso completo del file in cui salvare l'immagine\n","\n","  image_3d = torch.cat(list_val_output, dim=1) # Concatena le slice lungo la dimensione dei canali\n","  image_3d_numpy = image_3d.squeeze().cpu().numpy().transpose(1,2,0) # trasforma image_3d in un array numpy - image_3d_numpy.shape --> (256,256,32)\n","  \n","  nrrd.write(file_path, image_3d_numpy) # scrivi l'array NumPy in un file .nrrd"]},{"cell_type":"markdown","source":["Codice per salvare le immagini volumetriche **dopo l'applicazione del pre-processing**"],"metadata":{"id":"wpQvAUv7_Pgs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2rQwNNT8Fgw"},"outputs":[],"source":["eval_num = int(len(training_data)/batch_size) # definire numero di iterazioni per effettuare validazione ogni epoca \n","max_iterations = eval_num # numero massimo di batch da iterare\n","global_step = 1 \n","\n","x_3D= () #Inizializzazione della lista che conterrà le 256 slices che compongono il volume dell'immagine pre-processate\n","y_3D=() #Inizializzazione della lista che conterrà le 256 slices che compongono il volume delle maschere segmentate dall'operatore\n","\n","while global_step < max_iterations: # loop per richiamare la funzione train\n","  step = 0\n","  epoch_iterator = tqdm(train_loader, desc=\"Pre-processing (X / X Steps)\", dynamic_ncols=True, total=eval_num, position=0, leave=True) # crea un oggetto tqdm per tracciare l'avenzamento delle epoche\n","\n","  for step, batch in enumerate(epoch_iterator): # ad ogni ciclo for estrae una coppia step (numero dell'iterazione), batch (immagine e segmentazione) dal train loader\n","      step += 1\n","\n","      x1, y1 = (batch[\"image\"], batch[\"segmentation\"]) # manda i tensori di immagine e maschera alla GPU --> (32,1,256,256)\n","\n","      for i in range(batch_size):\n","        x2,y2 = x1[i,:,:,:], y1[i,:,:,:]  #Estrazione del primo elemento del batch --> Metatensor (1,256,256)\n","\n","        #Applicazione della funzione pre-processing\n","        x2,y2 = preprocessing(x2,y2) #--> x2/y2.size (256,256)\n","        \n","        Totensor = transforms.ToTensor() # permette di trasformare array numpy in tensori (Questa operazione ruota l'immagine)\n","        if i==0: # prima iterazione\n","          x = Totensor(x2)\n","          x = torch.unsqueeze(x,0).float() # aggiungo un canale\n","\n","          y = Totensor(y2)\n","          y = torch.unsqueeze(y,0)\n","        else: # successive iterazione\n","          x3 = Totensor(x2)\n","          x3 = torch.unsqueeze(x3,0).float()\n","          x = torch.row_stack((x,x3))\n","\n","          y3 = Totensor(y2)\n","          y3 = torch.unsqueeze(y3,0)\n","          y = torch.row_stack((y,y3))\n","\n","      #forma che ci aspettiamo --> [batch_size, channels, height, width] - x/y.shape --> (32,1,256,256)\n","\n","      tupla_x= torch.split(x, 1, dim=0) #dividere il tensore x in 32 tensori con shape [1,1,256,256]\n","      x_3D = x_3D + tupla_x #aggiunge la lista \"tupla_x\" alla lista x_3D\n","\n","      tupla_y= torch.split(y, 1, dim=0)\n","      y_3D = y_3D + tupla_x\n","\n","      if len(x_3D)==256: #Condizione per il salvataggio del volume 3D\n","        fdName = batch['image_meta_dict']['filename_or_obj'][-1][:-4]\n","        Savenrrd(x_3D,expFd2,fdName)\n","        x_3D=()\n","        y_3D=()\n","\n","      epoch_iterator.set_description(\"Pre-processing (%d / %d Steps)\" % (global_step, max_iterations)) # aggiorna il counter tqdm\n","\n","      global_step += 1"]},{"cell_type":"markdown","metadata":{"id":"fTLeXorgDduY"},"source":["# Funzione di **training**"]},{"cell_type":"markdown","source":["Funzione per il salvataggio delle immagini in formato .nrrd\n","\n","*   list_val_output: lista di tensori con shape [1,1,256,256]\n","*   stepFd: path della cartella all'interno della quale salvare le immagini\n","*   fdName: path dell'immagine\n"],"metadata":{"id":"TW8jMxr1_g0P"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"09LUK-RliY28"},"outputs":[],"source":["def Savenrrd(list_val_output,stepFd,fdName,intera):\n","  \n","  #Estrazione del nome dell'immagine a partire da fdName\n","  parts = fdName.split('/') # suddividi la stringa in base al separatore '/'\n","  parts = parts[4:] # elimina la prima parte della lista\n","  string = '/'.join(parts) # ricostruisci la stringa eliminando la parte specificata\n","\n","  file_path = os.path.join(stepFd, '{}.nrrd'.format(string[:-4] + '_output')) # crea il percorso completo del file in cui salvare l'immagine\n","\n","  image_3d_numpy = list_val_output.squeeze().cpu().numpy().transpose(1,2,0) # trasforma image_3d in un array numpy - image_3d_numpy.shape --> (256,256,32)\n","  \n","  nrrd.write(file_path, image_3d_numpy) # scrive l'array NumPy in un file .nrrd"]},{"cell_type":"markdown","source":["Funzione che permette di trasformare le matrici (256,256) numpy in tensori con dimensioni [batch_size, channels, height, width]\n","\n","*   x2: immagine 2D pre-processata (formato numpy) \n","*   y2: maschera manuale 2D (formato numpy) \n","*   i: indica l'i-esima immagine del batch\n","*   d: per indicare se si tratta di un operazione che viene svolta nel processo di pre o post-processing\n","*   tipo: per indicare se le immagini/maschere in input sono tensori o meno\n","*   x= tensore di immagini creato nell'iterazione precedente nel formato nel formato [batch_size, channels, height, width]\n","*   y= tensore di maschere creato nell'iterazione precedente nel formato [batch_size, channels, height, width]\n","\n","\n","\n"],"metadata":{"id":"T3XZcKwB_n-I"}},{"cell_type":"code","source":["def NumTensor(x2, y2, i, d,tipo, x=None, y=None):\n","  Totensor = transforms.ToTensor() # permette di trasformare array numpy in tensori (Questa operazione ruota l'immagine)\n","\n","  if d == 'pre': #operazioni che vengono applicate sulle immagini di pre-processing\n","  #---------  \n","    if tipo == 'N-3D': #operazioni che vengono eseguite quando x2 e y2 non sono tensore\n","      x3 = Totensor(x2).unsqueeze(0).float().to('cuda') #si utilizza la gpu\n","      y3 = Totensor(y2).unsqueeze(0).to('cuda')\n","    else: #operazioni che vengono eseguite quando x2 e y2 sono già tensore\n","      x3=x2\n","      y3=y2\n","\n","    if i == 0: # Prima iterazione\n","      x, y = x3, y3\n","    else: # Iterazioni successive\n","      x = torch.cat((x, x3), dim=0) #concatena i tensori x3 a x\n","      y = torch.cat((y, y3), dim=0)\n","  #---------  \n","  else: #operazioni che vengono applicate sulle immagini di post-processing\n","\n","    if tipo == 'N-3D': #operazioni che vengono eseguite quando x2 e y2 non sono tensore\n","      x3 = Totensor(x2).unsqueeze(0).float().to('cpu') #si utlizza la cpu\n","      y3 = Totensor(y2).unsqueeze(0).to('cpu')\n","    else: #operazioni che vengono eseguite quando x2 e y2 sono già tensore\n","      x3=x2\n","      y3=y2\n","\n","    if i == 0: # Prima iterazione\n","      x, y = x3, y3\n","    else: # Iterazioni successive\n","      x = torch.cat((x, x3), dim=0) #concatena i tensori x3 a x\n","      y = torch.cat((y, y3), dim=0)\n","  return x, y"],"metadata":{"id":"xTXT7KMM5wYG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJRFRODaDdSi"},"outputs":[],"source":["def train(global_step, train_loader, dice_val_3D_best,recall_val_3D_best,precision_val_3D_best, global_step_best):\n","\n","  model.train() # setta il modello in modalità training\n","  epoch_loss = 0\n","  step = 0\n","  x = torch.empty(32, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [32,1,256,256] per le immagini in output alla funzione di pre-processing\n","  y = torch.empty(32, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [32,1,256,256] per le maschere manuali in output alla funzione di pre-processing\n","\n","  epoch_iterator = tqdm(train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True,total=eval_num, position=0, leave=True) # crea un oggetto tqdm per tracciare l'avenzamento delle epoche\n","  \n","  for step, batch in enumerate(epoch_iterator): # ad ogni ciclo for estrae una coppia step (numero dell'iterazione), batch (immagine e segmentazione) dal train loader\n","    step += 1\n","\n","    x1, y1 = (batch[\"image\"].cuda(), batch[\"segmentation\"].cuda()) # manda i tensori di immagine e maschera alla GPU --> (32,1,256,256)\n","\n","    for i in range(batch_size):\n","      x2,y2 = x1[i,:,:,:], y1[i,:,:,:]  #prendo il primo elemento del batch --> (1,256,256)\n","\n","      #Applicazione della funzione pre-processing\n","      x2,y2 = preprocessing(x2,y2) #--> x2/y2.size (256,256)\n","\n","      #Applicazione della funzione NumTensor\n","      x,y = NumTensor(x2, y2, i,d='pre',tipo='N-3D', x=x, y=y) # --> x/y.shape (32,1,256,256) [batch_size, channels, height, width]\n","\n","    optimizer.zero_grad() # resetta i gradienti dell'optimizer\n","    logit_map = model(x) #l'immagine x viene data in input al modello\n","    loss = loss_function(logit_map, y) # calcolo della loss\n","    loss.backward() # effettua la backpropagation della loss\n","    epoch_loss += loss.item() # accumula i valori delle loss nei vari batch\n","    optimizer.step() # calcola i gradienti e aggiorna l'optimizer\n","\n","    epoch_iterator.set_description(\"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss)) # aggiorna il counter tqdm\n","\n","    if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations: # condizione per effettuare la validazione\n","        GB = global_step\n","\n","        dice_val_3D,recall_val_3D,precision_val_3D = validation(GB) # richiama la funzione di validazione per estrarre le metriche da valutare sul validation set\n","\n","        epoch_loss /= step # divide la loss in base al numero del batch\n","        epoch_loss_values.append(epoch_loss) # salva i valori della loss\n","\n","        metric_values_dice_3D.append(dice_val_3D) # salva i valori della metrica dice 3D\n","        metric_values_precision_3D.append(precision_val_3D) # salva i valori della metrica precision 3D\n","        metric_values_recall_3D.append(recall_val_3D) # salva i valori della metrica recall 3D\n","        \n","        if dice_val_3D > dice_val_3D_best: # salvataggio del modello se la metrica di validazione è migliorata\n","          best_epoca= int(global_step/eval_num)\n","          dice_val_3D_best = dice_val_3D\n","          precision_val_3D_best = precision_val_3D\n","          recall_val_3D_best = recall_val_3D\n","\n","          global_step_best = global_step\n","          torch.save( model.state_dict(), os.path.join(path, \"best_metric_model.pth\"))\n","          \n","          print(\"\\nModello salvato! - Immagini 3D: Miglior Dice medio: {} (Epoca {}) - Miglior Precision media: {} - Miglior Recall media: {} - Attuale Dice medio: {} (Epoca {})\\n\".format(dice_val_3D_best,best_epoca,precision_val_3D_best,recall_val_3D_best, dice_val_3D,int(global_step/eval_num)))\n","        else:\n","          print(\"\\nModello non salvato! - Immagini 3D: Miglior Dice medio: {}.       - Miglior Precision media: {} - Miglior Recall media: {} - Attuale Dice medio: {} (Epoca {})\\n\".format(dice_val_3D_best,precision_val_3D_best,recall_val_3D_best, dice_val_3D,int(global_step/eval_num)))\n","            \n","    global_step += 1\n","             \n","  return global_step, dice_val_3D_best,recall_val_3D_best,precision_val_3D_best, global_step_best"]},{"cell_type":"markdown","metadata":{"id":"76JH0SHfDhkN"},"source":["# Funzione di **validation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNi0xWbfDrPd"},"outputs":[],"source":["def validation(GB):\n","  model.eval() # setta il modello in moadlità inference\n","  \n","  epoch_val_loss = 0\n","  dice_3D= 0 #Inizializzazione del coefficiente di Dice 3D\n","  contatore_3D=0 #Inizializzazione di un contatore che possa aiutare durante la creazione dei metatensori per i volumi 3D\n","\n","  dice_vals_3D = list() #Inizializzazione della lista che conterrà i valori di dice per ogni volume 3D\n","  precision_vals_3D = list() #Inizializzazione della lista che conterrà i valori di precision per ogni volume 3D\n","  recall_vals_3D = list() #Inizializzazione della lista che conterrà i valori di recall per ogni volume 3D\n","\n","  val_inputs = torch.empty(32, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [32,1,256,256] per le immagini in output alla funzione di pre-processing\n","  val_labels4 = torch.empty(32, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [32,1,256,256] per le maschere manuali in output alla funzione di pre-processing\n","  val_outputs = torch.empty(32, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [32,1,256,256] per le maschere automatiche in output alla funzione di post-processing\n","  val_labels = torch.empty(32, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [32,1,256,256] per le maschere manuali in output alla funzione di post-processing\n","  val_outputs_3D = torch.empty(32, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [32,1,256,256] per le maschere automatiche per la generazione di un Metatensore nel formato [256,1,256,256] che contenga tutti i tensori di un volume 3D \n","  val_labels_3D = torch.empty(32, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [32,1,256,256] per le maschere manuali per la generazione di un Metatensore nel formato [256,1,256,256] che contenga tutti i tensori di un volume 3D \n","\n","  epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X Steps) (dice=X.X)\", dynamic_ncols=True, total=int(len(validation_data)/batch_size) ,position=0, leave=True) \n","          \n","  with torch.no_grad():\n","    for stepv, batch in enumerate(epoch_iterator_val):\n","      stepv += 1\n","      \n","      val_inputs1, val_labels1 = (batch[\"image\"].to(device), batch[\"segmentation\"].to(device)) # manda i tensori di immagine e maschera alla GPU --> (32,1,256,256)\n","      \n","      #PRE-PROCESSING\n","      for i in range(batch_size):\n","        val_inputs0,val_labels0 = val_inputs1[i,:,:,:], val_labels1[i,:,:,:] #val_inputs0/val_labels0.shape --> (1,256,256)\n","\n","        #Applicazione della funzione pre-processing\n","        val_inputs2,val_labels5 = preprocessing(val_inputs0,val_labels0) # val_inputs2/val_labels5.size --> (256,256)\n","\n","        #Applicazione della funzione NumTensor\n","        val_inputs,val_labels4 = NumTensor(val_inputs2, val_labels5, i,d='pre',tipo='N-3D', x=val_inputs, y=val_labels4) # val_inputs/val_labels4.shape --> (32,1,256,256) [batch_size, channels, height, width]\n","      \n","      val_outputs4 = inferer(val_inputs, model) # applicazione del modello all'input val_outputs4.shape--> (32,1,256,256)\n","\n","      loss_val = loss_function(val_outputs4, val_labels4) # calcolo della loss\n","      epoch_val_loss += loss_val.item()\n","\n","      val_outputs4 = [post_pred(i) for i in decollate_batch(val_outputs4.squeeze())] # scompone il tenosore nelle varie slice\n","      val_labels4  = [post_label(i) for i in decollate_batch(val_labels4.squeeze())] # lista di 32 item contenente un MetaTensor con shape [256,256]\n","      val_inputs  = [post_image(i) for i in decollate_batch(val_inputs.squeeze())]\n","\n","      #POST-PROCESSING\n","      for i in range(batch_size):\n","        val_outputs2,val_labels2,val_inputs2 = val_outputs4[i], val_labels4[i],val_inputs[i] # tensori con shape [256,256]\n","\n","        #Applicazione della funzione post-processing\n","        val_outputs2,val_labels2,val_inputs2 = postprocessing(val_outputs2,val_labels2, val_inputs2) #Post-processing\n","\n","        #Applicazione della funzione NumTensor\n","        val_outputs,val_labels = NumTensor(val_outputs2, val_labels2, i,d='post',tipo='N-3D', x=val_outputs, y=val_labels) # val_outputs/val_labels.shape --> (32,1,256,256)\n","\n","      #Applicazione della funzione NumTensor  \n","      val_outputs_3D,val_labels_3D = NumTensor(val_outputs, val_labels, contatore_3D,d='post',tipo='3D', x=val_outputs_3D, y=val_labels_3D)\n","      contatore_3D += 1\n","\n","      if val_outputs_3D.shape[0] == 256: # Condizione per l'azzeramento del contatore_3D\n","        contatore_3D=0\n","        \n","        if dice_val_3D_best>=0.65: #Condizione per il salvataggio delle del volume 3D\n","          stepFd = os.path.join(expFd, 'Epoca ' + str(int(GB/eval_num))) #Creazione della cartella che conterrà le immagini i volumi 3D per una specifica epoca\n","          if not os.path.isdir(stepFd):\n","            os.mkdir(stepFd)\n","\n","          fdName = batch['image_meta_dict']['filename_or_obj'][-1][:-4] #path dell'immagine \n","          Savenrrd(val_outputs_3D,stepFd,fdName) #Applicazione della funzione Savenrrd per il salvataggio dei volumi\n","        \n","        #Calcolo del Dice di un intera immagine 3D\n","        dice_metric_3D(y_pred=val_outputs_3D, y=val_labels_3D)\n","        dice_3D = dice_metric_3D.aggregate().item() #Valore di Dice su 256 slices\n","        dice_vals_3D.append(dice_3D)\n","\n","        #Calcolo della precision di un intera immagine 3D\n","        precision_metric_3D(y_pred=val_outputs_3D, y=val_labels_3D)\n","        precision_3D = precision_metric_3D.aggregate() #Valore di Precision su 256 slices\n","        precision_3D = precision_3D[0].item()\n","        precision_vals_3D.append(precision_3D)\n","\n","        #Calcolo della recall di un intera immagine 3D\n","        recall_metric_3D(y_pred=val_outputs_3D, y=val_labels_3D)\n","        recall_3D = recall_metric_3D.aggregate() #Valore di Recall su 256 slices\n","        recall_3D = recall_3D[0].item()\n","        recall_vals_3D.append(recall_3D)  \n","\n","        val_outputs_3D.zero_()\n","        val_labels_3D.zero_()\n","\n","      epoch_iterator_val.set_description(\"Validate (%d Steps) (dice 3D=%2.5f)\" % (stepv, dice_3D))  \n","\n","    dice_metric_3D.reset()\n","    recall_metric_3D.reset()\n","    precision_metric_3D.reset()\n","    epoch_val_loss /= stepv\n","    epoch_val_loss_values.append(epoch_val_loss)\n","\n","  #Dice    \n","  mean_dice_val_3D = np.mean(dice_vals_3D) #media delle medie dei valori di dice di tutte e 8 le immagini di validation\n","\n","  #Precision\n","  mean_precision_val_3D = np.mean(precision_vals_3D) #media delle medie dei valori di precision di tutte e 8 le immagini di validation\n","  \n","  #Recall\n","  mean_recall_val_3D = np.mean(recall_vals_3D) #media delle medie dei valori di recall di tutte e 8 le immagini di validation\n","\n","  return mean_dice_val_3D,mean_recall_val_3D,mean_precision_val_3D"]},{"cell_type":"markdown","metadata":{"id":"rodKIAeFGzYt"},"source":["# **Training** della rete"]},{"cell_type":"markdown","metadata":{"id":"dLX9ZA62G4_d"},"source":["**Inizializzazione dei parametri** per l'allenamento della rete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zk06NATaG2nR"},"outputs":[],"source":["eval_num = int(len(training_data)/batch_size) #numero di iterazioni per effettuare validazione ogni epoca \n","max_iterations = 65*eval_num # numero massimo di batch da iterare\n","global_step = 1\n","best_epoca = 0\n","\n","dice_metric_3D = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n","recall_metric_3D = ConfusionMatrixMetric(include_background=True, metric_name='sensitivity', compute_sample=False, reduction=\"mean\", get_not_nans=False) \n","precision_metric_3D = ConfusionMatrixMetric(include_background=True, metric_name='precision', compute_sample=False, reduction=\"mean\", get_not_nans=False)\n","\n","dice_val_3D_best = 0.0\n","precision_val_3D_best = 0.0\n","recall_val_3D_best = 0.0\n","global_step_best = 0\n","\n","epoch_loss_values = []\n","epoch_val_loss_values = []\n","metric_values_dice_3D = []\n","metric_values_precision_3D = []\n","metric_values_recall_3D = []"]},{"cell_type":"markdown","metadata":{"id":"or0e8waNG7LC"},"source":["**Training della rete**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdJfkHt3G9eu"},"outputs":[],"source":["from tqdm.notebook import tqdm\n","\n","while global_step < max_iterations: # loop per richiamare la funzione train \n","    global_step, dice_val_3D_best,recall_val_3D_best,precision_val_3D_best, global_step_best = train(\n","        global_step, train_loader, dice_val_3D_best,recall_val_3D_best,precision_val_3D_best, global_step_best)    \n"]},{"cell_type":"markdown","metadata":{"id":"fhlBSzukHBxE"},"source":["# Risultati DICE e LOSS"]},{"cell_type":"markdown","metadata":{"id":"Pu3ngZpCUTnp"},"source":["Caricamento di \"best_metric_model\"\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-Pc5hV6USmC"},"outputs":[],"source":["#model.load_state_dict(torch.load(os.path.join(current_dir, \"best_metric_model.pth\"))) # carichiamo il modello salvato"]},{"cell_type":"markdown","metadata":{"id":"F3UCCjpCUZxJ"},"source":["Plot loss e dice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zzgyzICHE-S"},"outputs":[],"source":["plt.figure(\"train\", (20, 6))\n","\n","#Plot Loss\n","plt.subplot(1, 4, 1)\n","plt.title(\"Iteration Average Loss\")\n","x_ = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n","y = epoch_loss_values\n","y1 = epoch_val_loss_values\n","plt.xlabel(\"Iteration\")\n","plt.plot(x_, y,label=\"train BCE\")\n","plt.plot(x_,y1,label=\"val BCE\")\n","plt.legend(loc=\"upper right\")\n","\n","#Plot Dice\n","plt.subplot(1, 4, 2)\n","plt.title(\"Val Mean Dice 3D\")\n","x_ = [eval_num * (i + 1) for i in range(len(metric_values_dice_3D))]\n","y = metric_values_dice_3D\n","plt.xlabel(\"Iteration\")\n","plt.plot(x_, y,color='orange')\n","\n","#Plot Precision\n","plt.subplot(1, 4, 3)\n","plt.title(\"Val Mean Precision 3D\")\n","\n","x_p_3D = [eval_num * (i + 1) for i in range(len(metric_values_precision_3D))]\n","y_p_3D = metric_values_precision_3D\n","plt.xlabel(\"Iteration\")\n","plt.plot(x_p_3D, y_p_3D,color='gray')\n","\n","#Plot recall\n","plt.subplot(1, 4, 4)\n","plt.title(\"Val Mean Recall 3D\")\n","\n","x_p_3D = [eval_num * (i + 1) for i in range(len(metric_values_recall_3D))]\n","y_p_3D = metric_values_recall_3D\n","plt.xlabel(\"Iteration\")\n","plt.plot(x_p_3D, y_p_3D,color='yellow')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["vRI75G7uT9YI","kuu_l8ExVSIw","Ictw2yudbq7E","DlrkomGX430P","8nYuKeHYi4u3","hF1AjY2WB-gQ","74dWE_JN7_zC","fTLeXorgDduY","76JH0SHfDhkN","rodKIAeFGzYt","fhlBSzukHBxE"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}