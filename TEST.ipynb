{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ri2p_QV2j3bc","9nWLDQONj0WA","TeGuTmiD3Onj","kTtdfWTdyzOa","LgpLHx9Sdikn","MeGhrudrdn7j","rhb3MDKYZBI1","vDDAbIMw3WBB","mWruKcLlxsUo"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# INSERIRE IL PATH DEL DATASET DA ESTRARRE\n","!unzip \"/content/drive/MyDrive/CONSEGNA CHALLENGE/TEST(1).zip\""],"metadata":{"id":"JdylwJd2P28y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# INSTALLAZIONE DI MONAI"],"metadata":{"id":"ri2p_QV2j3bc"}},{"cell_type":"code","source":["!pip install 'monai[all]'\n","!pip install pynrrd"],"metadata":{"id":"M-xUbvcaXZv0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LIBRERIE UTILIZZATE"],"metadata":{"id":"9nWLDQONj0WA"}},{"cell_type":"code","source":["import os\n","from monai.inferers import SimpleInferer\n","import nrrd\n","\n","from monai.utils import set_determinism\n","from monai.networks.nets import UNet\n","from monai.networks.layers import Norm\n","from monai.config import print_config\n","from monai.losses.dice import DiceCELoss\n","from monai.metrics import DiceMetric,ConfusionMatrixMetric\n","from skimage import measure\n","from scipy.stats import ks_2samp\n","import matplotlib.patches as mpatches\n","\n","import monai\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch \n","\n","from tqdm import tqdm\n","from skimage.io import imread, imshow, imsave\n","from skimage.transform import resize\n","\n","from skimage.transform import rotate\n","from scipy.ndimage import binary_fill_holes\n","from scipy.ndimage import binary_dilation, binary_erosion\n","\n","\n","import skimage.io as io\n","from skimage.measure import label, regionprops, regionprops_table\n","from skimage import morphology,exposure\n","\n","\n","import torch\n","from torchvision import transforms\n","from monai.utils import first\n","from monai.transforms import (\n","    AsDiscrete,\n","    EnsureChannelFirst,\n","    DataStatsd,\n","    AddChanneld,\n","    Compose,\n","    Activations,\n","    LoadImage,\n","    LoadImaged,\n","    Resize,\n","    Resized,\n","    DataStats,\n","    AsChannelFirstd,\n","    AsDiscreted,\n","    ToTensord,\n","    ToTensor,\n","    EnsureType,\n","    EnsureChannelFirstd,\n","    DataStatsd,\n","    AddChannel,\n","    AdjustContrastd,\n",")\n","\n","from monai.data import (\n","    DataLoader,\n","    CacheDataset,\n","    PILReader,\n","    ITKReader,\n","    NrrdReader,\n","    IterableDataset,\n","    decollate_batch,\n","    ArrayDataset\n",")\n","\n","from scipy.ndimage import median_filter\n","from scipy.ndimage import gaussian_filter\n"],"metadata":{"id":"sI2K34zUQmUC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DEFINIZIONE DEI PATH"],"metadata":{"id":"TeGuTmiD3Onj"}},{"cell_type":"code","source":["current_dir = os.getcwd()\n","Nome_cartella = 'CODICI FINALI' #nome della cartella caricata contenente lo script submission e il modello\n","Nome_best_metric_model = 'best_metric_model.pth' #nome del modello\n","\n","Nome_cartella_immagine = 'volumes' #inserire il nome della cartella contenente le immagini di test\n","Nome_cartella_maschere = 'mask'   #inserire il nome della cartella contenente le maschere di test\n","\n","path = os.path.join(current_dir,'drive/MyDrive', Nome_cartella)  #creazione del path utile all'interno dello script\n","\n","TEST_volumes_path = os.path.join(current_dir,Nome_cartella_immagine) #path associato alle immagini di test\n","TEST_mask_path    = os.path.join(current_dir,Nome_cartella_maschere) #path associato alle maschere correlate alle immagini del test\n","\n","# creazione delle liste ordinate \n","test_volumes = sorted(os.listdir(TEST_volumes_path))\n","test_masks =   sorted(os.listdir(TEST_mask_path))"],"metadata":{"id":"vnHvUi7JR6Jm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creazione del test set dict"],"metadata":{"id":"cx1S7EfrHSOF"}},{"cell_type":"code","source":["test_data = [] # Inizializzazione della lista di tris di immagini di test\n","for i in range(len(test_volumes)): #ciclo sul primo set di immagini di test \n","    tempDict = {\n","        'image': os.path.join(TEST_volumes_path, test_volumes[i]),\n","        'segmentation': os.path.join(TEST_mask_path, test_masks[i])}\n","    \n","    test_data.append(tempDict)"],"metadata":{"id":"T33Id9wOVmBu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MODELLO DELLA RETE"],"metadata":{"id":"kTtdfWTdyzOa"}},{"cell_type":"code","source":["# Definiamo il device da utilizzare: GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = UNet(\n","    spatial_dims=2,\n","    in_channels=1,\n","    out_channels=1,\n","    channels=(16, 32, 64, 128, 256),\n","    strides=(2, 2, 2, 2),\n","    num_res_units=2,\n","    norm=Norm.BATCH, \n",").to(device)\n","\n","# Definizione della loss function\n","loss_function = DiceCELoss(sigmoid = True)\n","torch.backends.cudnn.benchmark = True\n","\n","# Definizione dell'ottimizatore\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","\n","# Definizione delle trasformazioni di post-processing\n","post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)]) \n","post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])\n","post_image = Compose([EnsureType()])\n","\n","# Definizione del tipo di Inferenza da applicare con il modello allenato\n","inferer = SimpleInferer()\n","\n","# Definizione un seed per renderere ripetibili tutte le opearazioni che andiamo ad effettuare\n","# Questa operazione non è sempre possibile in quanto alcune operazioni hanno condizioni aleatorie intrinseche,\n","# in quel caso possono essere segnalati errori e warning che risolviamo eliminando questa condizione\n","set_determinism(seed=46)"],"metadata":{"id":"QnHAlpZ8YAnq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CARICAMENTO DEL MODELLO"],"metadata":{"id":"LgpLHx9Sdikn"}},{"cell_type":"code","source":["model.load_state_dict(torch.load(os.path.join(path, Nome_best_metric_model), map_location=torch.device('cpu')))"],"metadata":{"id":"JAzkwtxcRqyJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677594429866,"user_tz":-60,"elapsed":562,"user":{"displayName":"Cont est","userId":"12913621564358958738"}},"outputId":"595281d6-c655-417d-be2f-738a3f18075c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# DIMENSIONI ORIGINALI DELLE SLICES"],"metadata":{"id":"MeGhrudrdn7j"}},{"cell_type":"code","source":["dim_originali_test=[] #Inizializzazione di una lista che conterra le dimensioni originali delle immagini del test set\n","\n","for ind in range(len(test_data)): #iterazione sulla lunghezza del test set e, per ogni iterazione, si effettua:\n","  input_image = nrrd.read(test_data[ind][\"image\"]) #lettura dell'immagine volumetrica\n","  input_image=input_image[0]\n","  dim_originali_test.append((input_image.shape[1],input_image.shape[2]))  #lista che contiene le dimensioni originali delle slice di ogni volume"],"metadata":{"id":"q1zCAVDQb-WZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PRE PROCESSING e POST PROCESSING"],"metadata":{"id":"rhb3MDKYZBI1"}},{"cell_type":"markdown","source":["Funzione che permette di generare una maschera binaria, tramite la tecnica del global thresholding, a partire dall'immagine pre elaborata.\n","\n","\n","*   x: immagine 2D pre-processata\n","*   Threshold: soglia per il global thresholding\n","\n","\n","\n"],"metadata":{"id":"sx5BID0FqDCJ"}},{"cell_type":"code","source":["def img_to_mask(x,threshold):\n","  mask= x.copy()\n","  mask[mask<threshold] = 0\n","  mask[mask>threshold] = 1\n","  return mask"],"metadata":{"id":"H1yjfhCR3Uqc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Funzione che permette di gestire gli artefatti di tipo lineare\n","\n","*   x: immagine 2D pre-processata\n","*   mask: maschera ottenuta dalla funzione img_to_mask\n","\n"],"metadata":{"id":"BHPRTmS73nSc"}},{"cell_type":"code","source":["def delartifact(x,mask):\n","  kernel = np.ones((3,3)) #Definizione dell'elemento strutturale (kernel 3x3)\n","  dilated = binary_dilation(mask, structure=kernel) # Dilatazione degli elementi con intensità di pixel=1\n","  mask = binary_fill_holes(mask) #riempimento degli spazi vuoti all'interno delle segmentazioni\n","  mask = binary_erosion(dilated,structure=kernel) # Erosione degli elementi con intensità di pixel=1\n","\n","  image_mask = x*mask #Maschera sovrapposta all'immagine\n","  regions = regionprops(label(mask),image_mask) # Calcola le proprietà delle regioni\n","\n","  for region in regions:\n","    tumor_coords = region.coords # Estrazione delle coordinate dei pixel all'interno della regione del tumore      \n","    minr, minc, maxr, maxc = region.bbox #Estrazione delle coordinate della bounding box\n","\n","    if ((maxr-minr)>50 and (maxc-minc)<35) or ((maxr-minr)>150 and (maxc-minc)<37) or ((maxr-minr)<37 and (maxc-minc)>150) or ((maxr-minr)>20 and (maxc-minc)<8): #Condizione per eliminare l'artefatto\n","      x[tumor_coords[:, 0], tumor_coords[:, 1]]=np.min(x) #eliminazione dell'artefatto dall'immagine\n","\n","  return x"],"metadata":{"id":"X7WAEVNZqCbr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definizione di una funzione di pre processing\n","\n","\n","*   x: immagine 2D originale\n","*   y: maschera manuale associata all'immagine x"],"metadata":{"id":"yPkY4mXL3zTT"}},{"cell_type":"code","source":["def preprocessing(x,y):\n","  \n","  #Eliminazione del canale --> (256,256)\n","  x = x.squeeze()\n","  y = y.squeeze()\n","\n","  #Conversione delle immagini in formato numpy\n","  x = x.cpu().numpy()\n","  y = y.cpu().numpy()\n","  \n","  #Applicazione del filtro mediano con dimensione del kernel pari a 3\n","  x = median_filter(x,3)\n","\n","  #Gestione degli artefatti\n","  mask = img_to_mask(x,1700)\n","  condizione = np.count_nonzero(mask)\n","  if condizione !=0: #se la maschera ha almeno un elemento uguale a 1\n","    x = delartifact(x,mask)\n","  \n","  return x,y"],"metadata":{"id":"XhAbzZYTZE6m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definizione di una funzione di post processing\n","\n","*   x: maschera automatica in output al modello \n","*   y: maschera manuale associata all'immagine z\n","*   z: immagine 2D pre-processata\n","*   dim: lista composta da tuple contenenti le dimensioni originali delle immagini\n","*   step: indice utilizzato per iterare nel set di immagini\n","\n"],"metadata":{"id":"x-mSqdpk3_Vz"}},{"cell_type":"code","source":["def postprocessing(x,y,z,dim,step):\n","\n","  x = x.cpu().numpy() # x: test_outputs_post (maschera automatica)\n","  y = y.cpu().numpy() # y: test_labels_post (maschera manuale)\n","  z = z.cpu().numpy() # z: test_inputs_post (immagine)\n","\n","  x = binary_fill_holes(x) # Rifinimento della segmentazione (riempimento dei buchi)   \n","\n","  # Ridimensionamento delle immagini e maschere con dimensioni originali \n","  x = np.resize(x,dim[step-1])\n","  y = np.resize(y,dim[step-1])\n","  z = np.resize(z,dim[step-1])\n","  \n","  return x,y,z"],"metadata":{"id":"xHiCQz7IZXad"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# FUNZIONE PER IL SALVATAGGIO\n","\n"],"metadata":{"id":"vDDAbIMw3WBB"}},{"cell_type":"markdown","source":["Funzione per il salvataggio delle immagini in formato .nrrd\n","\n","*   list_val_output: Tensore con shape [256,1,256,256]\n","*   stepFd: path della cartella all'interno della quale salvare i volumi\n","*   fdName: path dell'immagine"],"metadata":{"id":"6ICafQJz6opY"}},{"cell_type":"code","source":["expFd = os.path.join(path,'Test-image') #creazione della cartella in cui verranno salvate le maschere automatiche volumetriche\n","\n","if not os.path.isdir(expFd):\n","  os.mkdir(expFd) #crea la directory\n","\n","def Savenrrd(list_val_output,stepFd,fdName):\n","  \n","  #Estrazione del nome dell'immagine a partire da fdName\n","  parts = fdName.split('/') # suddivide la stringa in base al separatore '/'\n","  parts = parts[3:] # elimina la prima parte della lista\n","  string = '/'.join(parts) # ricostruisce la stringa eliminando la parte specificata\n","\n","  #per creare il file path dell'intero volume 3D \n","  file_path = os.path.join(stepFd, '{}.nrrd'.format(string + '_output')) # crea il percorso completo del file in cui salvare l'immagine\n","\n","  image_3d_numpy = list_val_output.squeeze().cpu().numpy().transpose(1,2,0) # trasforma image_3d in un array numpy - image_3d_numpy.shape --> (256,256,256)\n","  nrrd.write(file_path, image_3d_numpy) # scrive l'array NumPy in un file .nrrd"],"metadata":{"id":"7Vo_6wmqMSVz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# IMPUTAZIONE"],"metadata":{"id":"mWruKcLlxsUo"}},{"cell_type":"markdown","source":["Trasformazioni da applicare al set di Test"],"metadata":{"id":"U0ALptirmZp7"}},{"cell_type":"code","source":["test_transforms = Compose(\n","    [\n","        LoadImaged(keys=[\"image\",\"segmentation\"],image_only=False, reader=ITKReader()), # caricamento dell'immagine e della segmentazione\n","        EnsureChannelFirstd(keys=[\"image\",\"segmentation\"]), # aggiunge il canale all' immagine e alla segmentazione ottenendo il formato channel-first da (NxN) a (1xNxN)\n","        AdjustContrastd(keys=[\"image\"],gamma=1.5), # modifica il contrasto dell'immagine \n","        Resized(keys=[\"image\", \"segmentation\"], spatial_size=[256,256,256]), # resize dell'immagine a 256x256\n","        ToTensord(keys=[\"image\", \"segmentation\"]), # per portare immagini e segmentazioni da formato PIL a un torch tensor da dare in input alla rete\n","    ]\n",")\n","\n","# Creazione di dataset iterabili utili durante l'imputazione\n","test_ds = IterableDataset(data = test_data, transform = test_transforms)\n","test_loader = DataLoader(test_ds, batch_size=1, num_workers=0, pin_memory=True, shuffle=False)"],"metadata":{"id":"oAQWCawlxurW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Funzione che permette di trasformare le matrici (256,256) numpy in tensori con dimensioni [batch_size, channels, height, width]\n","\n","*   x2: immagine 2D pre-processata (formato numpy) \n","*   y2: maschera manuale 2D (formato numpy) \n","*   i: indica l'i-esima immagine del batch\n","*   d: per indicare se si tratta di un operazione che viene svolta nel processo di pre o post-processing\n","*   x: tensore di immagini creato nell'iterazione precedente nel formato nel formato [batch_size, channels, height, width]\n","*   y: tensore di maschere creato nell'iterazione precedente nel formato [batch_size, channels, height, width]"],"metadata":{"id":"LM3ox0496tlI"}},{"cell_type":"code","source":["def NumTensor(x2, y2, i, d, x=None, y=None):\n","  Totensor = transforms.ToTensor() # Questa operazione ruota l'immagine\n","\n","  if d == 'pre': #operazioni che vengono applicate sulle immagini di pre-processing\n","    x3 = Totensor(x2).unsqueeze(0).float().to('cuda') #si utilizza la gpu\n","    y3 = Totensor(y2).unsqueeze(0).to('cuda')\n","\n","    if i == 0: # Prima iterazione\n","      x, y = x3, y3\n","    else: # Iterazioni successive\n","      x = torch.cat((x, x3), dim=0) #concatena i tensori x3 a x\n","      y = torch.cat((y, y3), dim=0)\n","  else: #operazioni che vengono applicate sulle immagini di post-processing\n","    x3 = Totensor(x2).unsqueeze(0).float().to('cpu') #si utilizza la cpu\n","    y3 = Totensor(y2).unsqueeze(0).to('cpu')\n","\n","    if i == 0: # Prima iterazione\n","      x, y = x3, y3\n","    else: # Iterazioni successive\n","      x = torch.cat((x, x3), dim=0) #concatena i tensori x3 a x\n","      y = torch.cat((y, y3), dim=0)\n","  \n","  return x, y"],"metadata":{"id":"ify-W9cTBW_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definizione delle metriche"],"metadata":{"id":"Om-FDidca_G5"}},{"cell_type":"code","source":["dice_metric_3D = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n","recall_metric_3D = ConfusionMatrixMetric(include_background=True, metric_name='sensitivity', compute_sample=False, reduction=\"mean\", get_not_nans=False) \n","precision_metric_3D = ConfusionMatrixMetric(include_background=True, metric_name='precision', compute_sample=False, reduction=\"mean\", get_not_nans=False)"],"metadata":{"id":"Ugo07GWrbDvK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch_iterator = tqdm(test_loader, desc=\"Testing (X / X Steps)\", dynamic_ncols=True,total=len(test_data), position=0, leave=True) # crea un oggetto tqdm per tracciare l'avenzamento delle epoche\n","\n","dice_test_3D = []\n","precision_test_3D = []\n","recall_test_3D = []\n","\n","test_inputs = torch.empty(256, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [256,1,256,256] per le immagini in output alla funzione di pre-processing\n","test_labels = torch.empty(256, 1, 256, 256, device='cuda') #inizializzazione di un tensore vuoto nel formato [256,1,256,256] per le maschere manuali in output alla funzione di pre-processing\n","test_outputs_def = torch.empty(256, 1, 256, 256, device='cpu') #inizializzazione di un tensore vuoto nel formato [256,1,256,256] per le immagini in output alla funzione di post-processing\n","test_labels_def = torch.empty(256, 1, 256, 256, device='cpu') #inizializzazione di un tensore vuoto nel formato [256,1,256,256] per le maschere manuali in output alla funzione di post-processing\n","\n","with torch.no_grad():\n","  for step, batch in enumerate(epoch_iterator): # ad ogni ciclo for estrae una coppia step (numero dell'iterazione), batch (immagine e segmentazione) dal train loader\n","      step += 1\n","\n","      x0, y0 = (batch[\"image\"].to('cuda'), batch[\"segmentation\"].to('cuda')) # manda i tensori di immagine e maschera alla GPU --> (1,1,256,256,256)\n","      fdName = batch['image_meta_dict']['filename_or_obj'][-1][:-5] #nome dell'immagine\n","\n","      #PRE-PROCESSING\n","      for i in range(x0.shape[2]):\n","        test_inputs1,test_labels1 = x0[:,:,:,:,i], y0[:,:,:,:,i] # --> test_inputs1/test_labels1.shape (1,1,256,256)\n","        \n","        #Applicazione della funzione pre-processing\n","        test_inputs_pre,test_labels_pre = preprocessing(test_inputs1,test_labels1) #test_inputs_pre/test_labels_pre.shape (256,256)\n","        \n","        #Applicazione della funzione NumTensor\n","        test_inputs,test_labels = NumTensor(test_inputs_pre, test_labels_pre, i,d='pre', x=test_inputs, y=test_labels) # --> test_inputs.shape (256,1,256,256)  \n","      \n","      #INFERENCE: applicazione del modello all'input\n","      test_outputs0 = inferer(test_inputs, model) #--> (256,1,256,256)\n","\n","      test_outputs_dec = [post_pred(i) for i in decollate_batch(test_outputs0.squeeze())] #per riportare i tensori nella forma--> (256,256,256) \n","      test_labels_dec  = [post_label(i) for i in decollate_batch(test_labels.squeeze())] # scompone il tenosore nelle varie slice \n","      test_inputs_dec  = [post_image(i) for i in decollate_batch(test_inputs.squeeze())] # lista di 256 item contenente un MetaTensor con shape [256,256]\n","\n","\n","      #POST-PROCESSING\n","      for i in range(test_outputs0.shape[0]):\n","        test_outputs1,test_labels1,test_inputs1 = test_outputs_dec[i], test_labels_dec[i], test_inputs_dec[i] # tensori con shape [256,256]\n","        \n","        #Applicazione della funzione post-processing\n","        test_outputs_post,test_labels_post,test_inputs_post = postprocessing(test_outputs1,test_labels1, test_inputs1,dim_originali_test,step) #test_outputs_post.shape --> (256,256)\n","\n","        #Applicazione della funzione NumTensor\n","        test_outputs_def,test_labels_def = NumTensor(test_outputs_post, test_labels_post, i, d='post', x=test_outputs_def, y=test_labels_def) # --> test_inputs.shape (256,1,256,256)\n","        \n","\n","      #Calcolo del Dice di un intera immagine 3D\n","      dice_metric_3D(y_pred=test_outputs_def, y=test_labels_def)\n","      dice_3D = dice_metric_3D.aggregate().item() #Valore di Dice su 256 slices\n","      dice_test_3D.append(dice_3D) \n","\n","      #Calcolo della precision di un intera immagine 3D\n","      precision_metric_3D(y_pred=test_outputs_def, y=test_labels_def)\n","      precision_3D = precision_metric_3D.aggregate() #Valore di Precision su 256 slices\n","      precision_3D = precision_3D[0].item()\n","      precision_test_3D.append(precision_3D)\n","\n","      #Calcolo della recall di un intera immagine 3D\n","      recall_metric_3D(y_pred=test_outputs_def, y=test_labels_def)\n","      recall_3D = recall_metric_3D.aggregate() #Valore di Recall su 256 slices\n","      recall_3D = recall_3D[0].item()\n","      recall_test_3D.append(recall_3D) \n","\n","\n","      #SALVATAGGIO intera immagine 3D\n","      Savenrrd(test_outputs_def,expFd,fdName)\n","      epoch_iterator.set_description(\"Testing (%d / %d Steps)\" % (step, len(test_data))) # aggiorna il counter tqdm"],"metadata":{"id":"C2BgTc7ux3nw"},"execution_count":null,"outputs":[]}]}